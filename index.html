<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <title>128D vs 512D ArcFace ろかぷー顔認識リアルタイム比較</title>
  <link href="https://fonts.googleapis.com/css?family=Noto+Sans+JP:400,700&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Noto Sans JP', 'ヒラギノ角ゴ ProN', 'Meiryo', sans-serif;
      background: #f3f7f8;
      margin: 0;
      padding: 0;
    }
    h2 {
      margin-top: 32px;
      font-size: 2.2rem;
      color: #333;
      font-weight: 700;
      letter-spacing: 0.05em;
    }
    .totalsum {
      margin: 18px auto 18px auto;
      font-size: 1.3rem;
      font-weight: bold;
      background: #fff;
      color: #26a2a3;
      border-radius: 16px;
      box-shadow: 0 4px 16px #33b9bb22;
      width: 410px;
      padding: 12px 0 10px 0;
      letter-spacing: 0.05em;
      border: 2px solid #33b9bb22;
    }
    #controls {
      margin: 24px 0 16px 0;
      background: #fff;
      border-radius: 20px;
      box-shadow: 0 4px 16px #33b9bb22;
      padding: 22px 30px 18px 30px;
      display: inline-block;
      min-width: 370px;
      border: 2px solid #33b9bb11;
    }
    input[type="file"] {
      margin-bottom: 6px;
    }
    input[type="text"] {
      padding: 9px 16px;
      font-size: 1rem;
      border: 1.7px solid #b5e2e3;
      border-radius: 12px;
      outline: none;
      margin-right: 8px;
      transition: border 0.2s;
      width: 150px;
      background: #f7fafb;
    }
    input[type="text"]:focus {
      border-color: #33b9bb;
    }
    button {
      padding: 8px 20px;
      margin: 0 7px;
      font-size: 1rem;
      background: linear-gradient(90deg, #33b9bb 70%, #00A0E9 100%);
      color: #fff;
      font-weight: bold;
      border: none;
      border-radius: 14px;
      cursor: pointer;
      box-shadow: 0 2px 8px #33b9bb18;
      transition: background 0.2s, box-shadow 0.2s;
      letter-spacing: 0.06em;
    }
    button:disabled {
      background: #b5e2e3;
      cursor: not-allowed;
      color: #fff;
      opacity: 0.7;
    }
    button:hover:not(:disabled) {
      background: linear-gradient(90deg, #00A0E9 60%, #33b9bb 100%);
      box-shadow: 0 4px 12px #00A0E922;
    }
    .camrow {
      display: flex;
      justify-content: center;
      gap: 40px;
      margin-top: 16px;
      margin-bottom: 16px;
    }
    .cambox {
      background: #fff;
      border-radius: 22px;
      box-shadow: 0 4px 16px #33b9bb18;
      padding: 16px 24px 22px 24px;
      border: 2px solid #33b9bb11;
      min-width: 355px;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    .cambox h3 {
      font-size: 1.2rem;
      color: #26a2a3;
      margin-bottom: 12px;
      font-weight: 700;
    }
    video, canvas {
      border-radius: 12px;
      background: #f6fcfd;
      margin-bottom: 6px;
      border: 1.5px solid #b5e2e3;
    }
    .counters {
      margin: 12px 0 0 0;
      font-size: 1.09em;
      font-weight: 600;
      color: #333;
      letter-spacing: 0.03em;
    }
    .counters .ok { color: #33b9bb; }
    .counters .ng { color: #E94560; }
    .resultlog {
      margin-top: 14px;
      width: 96%;
      background: #f7fafb;
      border-radius: 10px;
      box-shadow: 0 2px 6px #33b9bb13;
      padding: 10px 12px 8px 12px;
      text-align: left;
      max-height: 155px;
      overflow-y: auto;
      font-size: 0.99rem;
      border: 1.5px solid #b5e2e3;
      color: #444;
      min-height: 36px;
    }
    #status {
      margin-top: 20px;
      font-size: 1.08rem;
      color: #00A0E9;
      font-weight: 600;
      letter-spacing: 0.05em;
    }
    .ok { color: #33b9bb; font-weight: bold;}
    .ng { color: #E94560; font-weight: bold;}
  </style>
</head>
<body>
  <h2>128D vs 512D ArcFace ろかぷー顔認識リアルタイム比較</h2>
  <div class="totalsum" id="sumtotal">128D認識OK: 0　NG: 0　|　512D認識OK: 0　NG: 0</div>
  <div id="controls">
    <input type="file" id="photoUpload" accept="image/*" />
    <input type="text" id="nameInput" placeholder="名前を入力" />
    <button id="registerBtn">登録</button>
    <button id="startBtn" disabled>カメラ開始</button>
  </div>
  <div class="camrow">
    <div class="cambox">
      <h3>128D（MITモデル／face-api.js標準）</h3>
      <video id="video128" width="320" height="240" autoplay muted></video>
      <canvas id="overlay128" width="320" height="240"></canvas>
      <div class="counters">
        <span class="ok">OK: <span id="cntok128">0</span></span>　
        <span class="ng">NG: <span id="cntng128">0</span></span>
      </div>
      <div class="resultlog" id="log128"></div>
    </div>
    <div class="cambox">
      <h3>512D（ArcFace ONNX）</h3>
      <video id="video512" width="320" height="240" autoplay muted></video>
      <canvas id="overlay512" width="320" height="240"></canvas>
      <div class="counters">
        <span class="ok">OK: <span id="cntok512">0</span></span>　
        <span class="ng">NG: <span id="cntng512">0</span></span>
      </div>
      <div class="resultlog" id="log512"></div>
    </div>
  </div>
  <div id="status">モデル読込中…</div>
  <!-- 必要ライブラリ -->
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <script type="module">
    const ARC_ONNX_URL = "./w600k_mbf.onnx";
    const video128 = document.getElementById('video128');
    const overlay128 = document.getElementById('overlay128');
    const ctx128 = overlay128.getContext('2d');
    const video512 = document.getElementById('video512');
    const overlay512 = document.getElementById('overlay512');
    const ctx512 = overlay512.getContext('2d');
    const statusEl = document.getElementById('status');
    const photoInput = document.getElementById('photoUpload');
    const nameInput = document.getElementById('nameInput');
    const regBtn = document.getElementById('registerBtn');
    const startBtn = document.getElementById('startBtn');
    const cntok128 = document.getElementById('cntok128');
    const cntng128 = document.getElementById('cntng128');
    const cntok512 = document.getElementById('cntok512');
    const cntng512 = document.getElementById('cntng512');
    const sumtotal = document.getElementById('sumtotal');
    // 各モデル用ログ領域
    const logDiv128 = document.getElementById('log128');
    const logDiv512 = document.getElementById('log512');
    let labeledName = null;
    let refVec128 = null;
    let refVec512 = null;
    let session512 = null;
    // ログは分割（128D・512D別々に10件ずつ保持）
    let logList128 = [];
    let logList512 = [];
    let ok128 = 0, ng128 = 0, ok512 = 0, ng512 = 0;

    function addLog(model, result, name) {
      const now = new Date();
      const hh = now.getHours().toString().padStart(2, '0');
      const mm = now.getMinutes().toString().padStart(2, '0');
      const ss = now.getSeconds().toString().padStart(2, '0');
      const time = `${hh}:${mm}:${ss}`;
      const status = result ? `<span class="ok">○認識</span>` : `<span class="ng">×不一致</span>`;
      const line = `${status} (${name}) <span style="color:#888">${time}</span>`;
      if(model=="128D"){
        if(result) ok128++; else ng128++;
        cntok128.textContent = ok128;
        cntng128.textContent = ng128;
        logList128.unshift(line);
        logDiv128.innerHTML = logList128.slice(0,10).join("<br>");
      }
      if(model=="512D"){
        if(result) ok512++; else ng512++;
        cntok512.textContent = ok512;
        cntng512.textContent = ng512;
        logList512.unshift(line);
        logDiv512.innerHTML = logList512.slice(0,10).join("<br>");
      }
      sumtotal.textContent = `128D認識OK: ${ok128}　NG: ${ng128}　|　512D認識OK: ${ok512}　NG: ${ng512}`;
    }

    async function loadModels() {
      statusEl.textContent = '128D・顔検出モデル読込中…';
      await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model');
      await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model');
      await faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model');
      statusEl.textContent = '512D ArcFaceモデル読込中…';
      session512 = await ort.InferenceSession.create(ARC_ONNX_URL);
      statusEl.textContent = '写真と名前を登録してください';
    }
    async function getVec128(image) {
      const det = await faceapi.detectSingleFace(image, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptor();
      return det ? { vec: det.descriptor, box: det.detection.box } : null;
    }
    async function getVec512(image) {
      const det = await faceapi.detectSingleFace(image, new faceapi.TinyFaceDetectorOptions());
      if (!det) return null;
      const box = det.box;
      const faceCanvas = document.createElement('canvas');
      faceCanvas.width = 112; faceCanvas.height = 112;
      const fctx = faceCanvas.getContext('2d');
      fctx.drawImage(image, box.x, box.y, box.width, box.height, 0, 0, 112, 112);
      const imgData = fctx.getImageData(0, 0, 112, 112).data;
      let input = new Float32Array(1 * 3 * 112 * 112);
      for (let y = 0; y < 112; y++) {
        for (let x = 0; x < 112; x++) {
          for (let c = 0; c < 3; c++) {
            input[y * 112 * 3 + x * 3 + c] = imgData[(y * 112 + x) * 4 + c] / 255.0;
          }
        }
      }
      const tensor = new ort.Tensor("float32", input, [1, 3, 112, 112]);
      const feeds = {};
      feeds['input.1'] = tensor;
      const outputs = await session512.run(feeds);
      let emb = outputs['embedding'] || outputs['fc1'] || outputs['output'] || Object.values(outputs)[0];
      if (!emb || !emb.data) return null;
      const norm = Math.sqrt(emb.data.reduce((s,v) => s+v*v, 0));
      const vec = emb.data.map(v => v/norm);
      return { vec: vec, box: box };
    }
    regBtn.addEventListener('click', async () => {
      const file = photoInput.files[0];
      const label = nameInput.value.trim();
      if (!file || !label) {
        alert('写真と名前の両方を入力してください');
        return;
      }
      const img = await faceapi.bufferToImage(file);
      const v128 = await getVec128(img);
      const v512 = await getVec512(img);
      if (!v128 || !v512) {
        statusEl.textContent = '顔が検出できません。別の写真でお試しください';
        return;
      }
      labeledName = label;
      refVec128 = v128.vec;
      refVec512 = v512.vec;
      ok128 = ng128 = ok512 = ng512 = 0;
      cntok128.textContent = 0; cntng128.textContent = 0; cntok512.textContent = 0; cntng512.textContent = 0;
      sumtotal.textContent = `128D認識OK: 0　NG: 0　|　512D認識OK: 0　NG: 0`;
      logList128 = [];
      logList512 = [];
      logDiv128.innerHTML = "";
      logDiv512.innerHTML = "";
      statusEl.textContent = `「${label}」を登録しました。カメラを開始できます`;
      startBtn.disabled = false;
    });
    startBtn.addEventListener('click', async () => {
      if (!refVec128 || !refVec512) {
        alert('先に写真と名前を登録してください');
        return;
      }
      startBtn.disabled = true;
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user', width: 320, height: 240 } });
      video128.srcObject = stream;
      video512.srcObject = stream;
      statusEl.textContent = 'カメラ起動中…';
      video128.onloadedmetadata = () => {
        video128.play();
        video512.play();
        runRecognition();
      };
    });
    function cosineSim(a, b) {
      let s = 0;
      for(let i=0;i<a.length;i++) s += a[i]*b[i];
      return s;
    }
    async function runRecognition() {
      statusEl.textContent = '認識待機中…';
      faceapi.matchDimensions(overlay128, { width: 320, height: 240 });
      faceapi.matchDimensions(overlay512, { width: 320, height: 240 });
      setInterval(async () => {
        // 128D
        const det128 = await faceapi.detectSingleFace(video128, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptor();
        ctx128.clearRect(0, 0, overlay128.width, overlay128.height);
        if (det128) {
          const sim = cosineSim(refVec128, det128.descriptor);
          const threshold = 0.45;
          let label = (sim > (1-threshold)) ? labeledName : 'Unknown';
          ctx128.strokeStyle = (label === 'Unknown') ? '#E94560' : '#33b9bb';
          ctx128.lineWidth = 3;
          const box = det128.detection.box;
          ctx128.strokeRect(box.x, box.y, box.width, box.height);
          ctx128.font = '20px Noto Sans JP, sans-serif';
          ctx128.fillStyle = ctx128.strokeStyle;
          ctx128.fillText(label, box.x, box.y > 24 ? box.y - 6 : box.y + 24);
          addLog("128D", (label !== 'Unknown'), label);
        } else {
          addLog("128D", false, "顔検出なし");
        }

        // 512D
        ctx512.clearRect(0, 0, overlay512.width, overlay512.height);
        const det512 = await faceapi.detectSingleFace(video512, new faceapi.TinyFaceDetectorOptions());
        if (det512) {
          // 顔画像をリサイズしてベクトル取得
          const box = det512.box;
          const faceCanvas = document.createElement('canvas');
          faceCanvas.width = 112; faceCanvas.height = 112;
          const fctx = faceCanvas.getContext('2d');
          fctx.drawImage(video512, box.x, box.y, box.width, box.height, 0, 0, 112, 112);
          const imgData = fctx.getImageData(0, 0, 112, 112).data;
          let input = new Float32Array(1 * 3 * 112 * 112);
          for (let y = 0; y < 112; y++) {
            for (let x = 0; x < 112; x++) {
              for (let c = 0; c < 3; c++) {
                input[y * 112 * 3 + x * 3 + c] = imgData[(y * 112 + x) * 4 + c] / 255.0;
              }
            }
          }
          const tensor = new ort.Tensor("float32", input, [1, 3, 112, 112]);
          const feeds = {};
          feeds['input.1'] = tensor;
          const outputs = await session512.run(feeds);
          let emb = outputs['embedding'] || outputs['fc1'] || outputs['output'] || Object.values(outputs)[0];
          if (!emb || !emb.data) {
            addLog("512D", false, "ベクトル取得失敗");
            return;
          }
          const norm = Math.sqrt(emb.data.reduce((s,v) => s+v*v, 0));
          const vec = emb.data.map(v => v/norm);
          const sim = cosineSim(refVec512, vec);
          const threshold = 0.45;
          let label = (sim > (1-threshold)) ? labeledName : 'Unknown';
          ctx512.strokeStyle = (label === 'Unknown') ? '#E94560' : '#33b9bb';
          ctx512.lineWidth = 3;
          ctx512.strokeRect(box.x, box.y, box.width, box.height);
          ctx512.font = '20px Noto Sans JP, sans-serif';
          ctx512.fillStyle = ctx512.strokeStyle;
          ctx512.fillText(label, box.x, box.y > 24 ? box.y - 6 : box.y + 24);
          addLog("512D", (label !== 'Unknown'), label);
        } else {
          addLog("512D", false, "顔検出なし");
        }
      }, 1200); // 1.2秒ごと認識
    }
    loadModels();
  </script>
</body>
</html>
